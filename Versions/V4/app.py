# app.py

import streamlit as st
import pandas as pd
import json
from datetime import datetime
import os
import sys
from collections import defaultdict
import plotly.express as px
from typing import List, Dict, Any

# Adiciona o diret√≥rio atual ao path para importa√ß√µes
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importa os m√≥dulos customizados
try:
    from data_processor import AzureLogProcessor
    from azure_log_analyzer import AzureLogAnalyzer
    from governance_analyzer import AdvancedGovernanceAnalyzer
    from visualization_generator import SecurityVisualizationGenerator
    from models import AIAnalysisResult, EnhancedAIAnalysisResult, DetailedFinding, RiskLevel, GovernanceViolationType
    from config import config
    # Novos imports para conectores Azure
    from azure_data_connectors import DataSourceConfig, DataConnectorFactory, UnifiedDataManager
    from enhanced_data_interface import render_enhanced_data_interface
    from kql_templates import KQLTemplateManager
except ImportError as e:
    st.error(f"‚ùå Erro ao importar m√≥dulos: {e}")
    st.error("Certifique-se de que todos os arquivos est√£o no mesmo diret√≥rio:")
    st.code("""
    - app.py
    - data_processor.py
    - azure_log_analyzer.py
    - governance_analyzer.py (NOVO)
    - visualization_generator.py
    - models.py (ATUALIZADO)
    - config.py
    """)
    st.stop()
except Exception as e:
    st.error(f"‚ùå Erro inesperado na importa√ß√£o: {e}")
    st.stop()

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="PrivIQ", 
    page_icon="üõ°Ô∏è", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado aprimorado
st.markdown("""
<style>
    .main-header {
        font-size: 2.8rem; font-weight: bold; color: #0078d4; 
        text-align: center; margin-bottom: 2rem;
        background: linear-gradient(90deg, #0078d4, #106ebe);
        -webkit-background-clip: text; -webkit-text-fill-color: transparent;
    }
    .metric-card {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.8rem; border-radius: 12px; margin: 1rem 0; 
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        border-left: 6px solid #0078d4;
        color: #212529;
        transition: transform 0.2s ease;
    }
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0,0,0,0.15);
    }
    .risk-Critical { 
        border-left-color: #8B0000; 
        background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
    }
    .risk-High { 
        border-left-color: #DC143C; 
        background: linear-gradient(135deg, #fff3e0 0%, #ffcc02 100%);
    }
    .risk-Medium { 
        border-left-color: #FF8C00; 
        background: linear-gradient(135deg, #fff8e1 0%, #ffecb3 100%);
    }
    .risk-Low { 
        border-left-color: #228B22; 
        background: linear-gradient(135deg, #f1f8e9 0%, #c8e6c9 100%);
    }
    .governance-summary {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        padding: 2rem; border-radius: 15px; margin: 2rem 0;
        border: 2px solid #2196f3;
    }
    .compliance-score {
        font-size: 3rem; font-weight: bold; text-align: center;
        padding: 1rem; border-radius: 10px; margin: 1rem 0;
    }
    .score-excellent { background-color: #4caf50; color: white; }
    .score-good { background-color: #8bc34a; color: white; }
    .score-fair { background-color: #ff9800; color: white; }
    .score-poor { background-color: #f44336; color: white; }
    .tabs-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def initialize_session_state():
    """Inicializa as vari√°veis de estado da sess√£o."""
    try:
        if 'analysis_result' not in st.session_state:
            st.session_state.analysis_result = None
        if 'enhanced_analysis_result' not in st.session_state:
            st.session_state.enhanced_analysis_result = None
        if 'logs_df' not in st.session_state:
            st.session_state.logs_df = None
        if 'processor' not in st.session_state:
            st.session_state.processor = AzureLogProcessor()
        if 'governance_summary' not in st.session_state:
            st.session_state.governance_summary = None
    except Exception as e:
        st.error(f"Erro ao inicializar sess√£o: {e}")
        # Fallback - inicializa manualmente
        st.session_state.analysis_result = None
        st.session_state.logs_df = None
        st.session_state.processor = None
        st.session_state.governance_summary = None

def render_governance_overview(summary: dict):
    """Renderiza vis√£o geral de governan√ßa."""
    st.markdown('<div class="governance-summary">', unsafe_allow_html=True)
    st.subheader("üìä Resumo Executivo de Governan√ßa")
    
    col1, col2, col3, col4 = st.columns(4)
    
    issues = summary.get('governance_issues', {})
    
    with col1:
        st.metric(
            "üö´ Viola√ß√µes SOD", 
            issues.get('sod_violations', 0),
            help="Segregation of Duties violations"
        )
        
    with col2:
        st.metric(
            "üë§ Atribui√ß√µes Diretas", 
            issues.get('direct_assignments', 0),
            help="Usu√°rios com roles atribu√≠das diretamente"
        )
        
    with col3:
        st.metric(
            "‚ö†Ô∏è Conflitos de Permiss√£o", 
            issues.get('permission_conflicts', 0),
            help="Conflitos de permiss√µes identificados"
        )
        
    with col4:
        st.metric(
            "üîÑ Grupos Duplicados", 
            issues.get('duplicate_groups', 0),
            help="Grupos com permiss√µes redundantes"
        )
    
    # Calcula score de compliance
    total_issues = sum(issues.values())
    total_events = summary.get('total_events', 1)
    compliance_score = max(0, 100 - (total_issues / total_events * 100))
    
    if compliance_score >= 90:
        score_class = "score-excellent"
        score_text = "EXCELENTE"
    elif compliance_score >= 75:
        score_class = "score-good" 
        score_text = "BOM"
    elif compliance_score >= 50:
        score_class = "score-fair"
        score_text = "REGULAR"
    else:
        score_class = "score-poor"
        score_text = "CR√çTICO"
    
    st.markdown(f"""
    <div class="compliance-score {score_class}">
        Score de Compliance: {compliance_score:.1f}%<br>
        <small>Status: {score_text}</small>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

def render_detailed_governance_reports(summary: dict):
    """Renderiza relat√≥rios detalhados de governan√ßa."""
    st.subheader("üìã Relat√≥rios Detalhados por Categoria")
    
    detailed = summary.get('detailed_analysis', {})
    
    # Relat√≥rio de Atribui√ß√µes Diretas
    with st.expander("üë§ Relat√≥rio: Atribui√ß√µes Diretas de Roles", expanded=False):
        direct_data = detailed.get('direct_assignments', {})
        assignments = direct_data.get('direct_assignments', [])
        
        if assignments:
            st.warning(f"‚ö†Ô∏è Identificadas {len(assignments)} atribui√ß√µes diretas de roles.")
            st.markdown("**Problema:** Atribui√ß√µes diretas de roles violam as melhores pr√°ticas de governan√ßa.")
            st.markdown("**Impacto:** Dificulta auditoria, controle de acesso e revoga√ß√£o de permiss√µes.")
            
            df_direct = pd.DataFrame(assignments)
            if not df_direct.empty:
                st.dataframe(
                    df_direct[['user', 'role', 'is_privileged', 'timestamp']].head(20),
                    width='stretch'
                )
                
                # Gr√°fico de roles mais atribu√≠das diretamente
                if 'role' in df_direct.columns:
                    role_counts = df_direct['role'].value_counts().head(10)
                    fig = px.bar(
                        x=role_counts.values, 
                        y=role_counts.index,
                        orientation='h',
                        title="Top 10 Roles Atribu√≠das Diretamente",
                        color=role_counts.values,
                        color_continuous_scale='Reds'
                    )
                    st.plotly_chart(fig, width='stretch')
            
            st.markdown("**Recomenda√ß√µes:**")
            st.markdown("- Migrar atribui√ß√µes diretas para grupos de seguran√ßa")
            st.markdown("- Implementar processo de aprova√ß√£o para atribui√ß√µes privilegiadas")
            st.markdown("- Revisar periodicamente todas as atribui√ß√µes diretas")
        else:
            st.success("‚úÖ Nenhuma atribui√ß√£o direta identificada.")

    # Relat√≥rio de Conflitos SOD
    with st.expander("üö´ Relat√≥rio: Viola√ß√µes de Segrega√ß√£o de Fun√ß√µes (SOD)", expanded=False):
        conflicts_data = detailed.get('conflicts', {})
        conflicts = conflicts_data.get('conflicts', [])
        sod_violations = [c for c in conflicts if c.get('type') == 'SOD_VIOLATION']
        
        if sod_violations:
            st.error(f"üö® Identificadas {len(sod_violations)} viola√ß√µes cr√≠ticas de SOD.")
            st.markdown("**Problema:** Usu√°rios possuem roles conflitantes que violam a segrega√ß√£o de fun√ß√µes.")
            st.markdown("**Impacto:** Alto risco de fraude, erro humano e viola√ß√µes de compliance.")
            
            for violation in sod_violations[:10]:  # Mostra top 10
                st.markdown(f"**üë§ {violation.get('user')}**")
                roles = violation.get('conflicting_roles', [])
                st.markdown(f"- Roles Conflitantes: `{' + '.join(roles)}`")
                st.markdown(f"- Severidade: **{violation.get('severity')}**")
                st.markdown("---")
            
            st.markdown("**Recomenda√ß√µes:**")
            st.markdown("- Remover imediatamente uma das roles conflitantes")
            st.markdown("- Implementar controles automatizados de SOD")
            st.markdown("- Definir matriz de roles incompat√≠veis")
        else:
            st.success("‚úÖ Nenhuma viola√ß√£o de SOD identificada.")

    # Relat√≥rio de Grupos Duplicados  
    with st.expander("üîÑ Relat√≥rio: Grupos com Permiss√µes Duplicadas", expanded=False):
        duplicates_data = detailed.get('duplicates', {})
        duplicates = duplicates_data.get('duplicates', [])
        
        if duplicates:
            st.warning(f"‚ö†Ô∏è Identificados {len(duplicates)} conjuntos de grupos duplicados.")
            st.markdown("**Problema:** Grupos diferentes possuem exatamente as mesmas permiss√µes.")
            st.markdown("**Impacto:** Complexidade desnecess√°ria na gest√£o de acesso e auditoria.")
            
            for dup in duplicates[:5]:  # Mostra top 5
                st.markdown(f"**Grupos com Permiss√µes Id√™nticas:**")
                st.markdown(f"- Grupos: `{', '.join(dup.get('groups', []))}`")
                st.markdown(f"- Roles Compartilhadas: `{', '.join(dup.get('shared_roles', []))}`")
                st.markdown(f"- Quantidade de Roles: {dup.get('roles_count', 0)}")
                st.markdown("---")
            
            st.markdown("**Recomenda√ß√µes:**")
            st.markdown("- Consolidar grupos com permiss√µes id√™nticas")
            st.markdown("- Revisar necessidade de m√∫ltiplos grupos")
            st.markdown("- Padronizar nomenclatura e estrutura de grupos")
        else:
            st.success("‚úÖ Nenhum grupo duplicado identificado.")

    # Relat√≥rio de Padr√µes Cr√≠ticos
    with st.expander("üîç Relat√≥rio: Padr√µes de Acesso Suspeitos", expanded=False):
        patterns_data = detailed.get('critical_patterns', {})
        patterns = patterns_data.get('critical_patterns', [])
        
        if patterns:
            st.error(f"üö® Identificados {len(patterns)} padr√µes suspeitos.")
            
            for pattern in patterns:
                pattern_type = pattern.get('type', 'UNKNOWN')
                severity = pattern.get('severity', 'MEDIUM')
                
                if pattern_type == 'AFTER_HOURS_ACCESS':
                    st.markdown("**üåô Acessos Fora do Hor√°rio Comercial**")
                    st.markdown(f"- Quantidade: {pattern.get('count', 0)} eventos")
                    st.markdown(f"- Usu√°rios: `{', '.join(pattern.get('users', [])[:5])}`")
                    
                elif pattern_type == 'MULTIPLE_IP_ADDRESSES':
                    st.markdown("**üåê M√∫ltiplos Endere√ßos IP**")
                    users_info = pattern.get('users', [])
                    for user_info in users_info[:5]:
                        st.markdown(f"- {user_info.get('user')}: {user_info.get('ip_count')} IPs diferentes")
                        
                elif pattern_type == 'EXCESSIVE_FAILED_ATTEMPTS':
                    st.markdown("**‚ùå Tentativas de Acesso Falhadas**")
                    users_info = pattern.get('users', [])
                    for user_info in users_info[:5]:
                        st.markdown(f"- {user_info.get('user')}: {user_info.get('failures')} falhas")
                
                st.markdown(f"- **Severidade:** {severity}")
                st.markdown("---")
            
            st.markdown("**Recomenda√ß√µes:**")
            st.markdown("- Investigar atividades fora do hor√°rio comercial")
            st.markdown("- Implementar alertas de seguran√ßa automatizados")
            st.markdown("- Revisar pol√≠ticas de acesso condicional")
        else:
            st.success("‚úÖ Nenhum padr√£o suspeito identificado.")

def render_detailed_report(result: AIAnalysisResult):
    """Renderiza o relat√≥rio detalhado da IA com melhorias."""
    st.subheader("ü§ñ An√°lise Inteligente de Seguran√ßa")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        st.markdown("**Resumo Executivo da IA:**")
        st.info(f"*{result.risk_assessment.summary}*")
    with col2:
        score = result.risk_assessment.score
        score_color = "#8B0000" if score >= 80 else "#FF4500" if score >= 60 else "#FF8C00" if score >= 40 else "#228B22"
        st.markdown(f'<div style="background-color: {score_color}; color: white; padding: 1rem; border-radius: 10px; text-align: center;"><h3>Score: {score}/100</h3></div>', unsafe_allow_html=True)

    st.markdown("---")
    
    if result.findings:
        # Agrupa findings por categoria
        findings_by_category = defaultdict(list)
        for finding in result.findings:
            category = "SOD" if "sod" in finding.title.lower() or "segreg" in finding.title.lower() else \
                      "Direct Assignment" if "direct" in finding.title.lower() else \
                      "Excessive Privileges" if "excess" in finding.title.lower() or "privileg" in finding.title.lower() else \
                      "Duplicate Groups" if "duplic" in finding.title.lower() or "grupo" in finding.title.lower() else \
                      "Suspicious Activity"
            findings_by_category[category].append(finding)
        
        st.write("**Problemas Identificados pela IA por Categoria:**")
        
        for category, findings in findings_by_category.items():
            with st.expander(f"üéØ {category} ({len(findings)} problemas)", expanded=True):
                for finding in findings:
                    st.markdown(f'<div class="metric-card risk-{finding.risk_level.value}">', unsafe_allow_html=True)
                    
                    col_title, col_risk = st.columns([4, 1])
                    with col_title:
                        st.markdown(f"### {finding.title}")
                    with col_risk:
                        risk_emoji = {"Critical": "üö®", "High": "‚ö†Ô∏è", "Medium": "‚ö°", "Low": "‚ÑπÔ∏è"}
                        st.markdown(f"**{risk_emoji.get(finding.risk_level.value, 'üìã')} {finding.risk_level.value}**")
                    
                    with st.expander("Ver detalhes completos", expanded=False):
                        st.markdown("**üìù Descri√ß√£o:**")
                        st.write(finding.description)
                        
                        st.markdown("**üí° Recomenda√ß√£o:**")
                        st.success(finding.recommendation)
                        
                        if finding.affected_principals:
                            st.markdown("**üë• Principais Afetados:**")
                            # Limita a exibi√ß√£o a 10 principais
                            principals_to_show = finding.affected_principals[:10]
                            for principal in principals_to_show:
                                st.markdown(f"- `{principal}`")
                            
                            if len(finding.affected_principals) > 10:
                                st.markdown(f"*... e mais {len(finding.affected_principals) - 10} principais*")
                    
                    st.markdown('</div>', unsafe_allow_html=True)
        
        # Resumo de recomenda√ß√µes consolidado
        st.markdown("---")
        st.subheader("üìã Plano de A√ß√£o Consolidado")
        recommendations_summary = generate_recommendations_summary(result)
        st.markdown(recommendations_summary)
        
    else:
        st.success("‚úÖ A IA n√£o identificou problemas significativos de governan√ßa.")

def generate_recommendations_summary(result: AIAnalysisResult) -> str:
    """Agrupa recomenda√ß√µes por tipo de achado para criar um plano de a√ß√£o."""
    if not result.findings:
        return "**‚úÖ Nenhuma a√ß√£o corretiva necess√°ria no momento.**"

    # Agrupa por categoria e prioridade
    recommendations_by_risk = defaultdict(lambda: defaultdict(set))
    
    for finding in result.findings:
        category = "SOD" if "sod" in finding.title.lower() or "segreg" in finding.title.lower() else \
                  "Atribui√ß√µes Diretas" if "direct" in finding.title.lower() else \
                  "Privil√©gios Excessivos" if "excess" in finding.title.lower() or "privileg" in finding.title.lower() else \
                  "Grupos Duplicados" if "duplic" in finding.title.lower() or "grupo" in finding.title.lower() else \
                  "Atividade Suspeita"
        
        recommendations_by_risk[finding.risk_level.value][category].add(finding.recommendation)
    
    markdown_summary = ["### üéØ A√ß√µes Priorit√°rias por N√≠vel de Risco\n"]
    
    # Ordena por prioridade
    risk_order = ["Critical", "High", "Medium", "Low"]
    
    for risk_level in risk_order:
        if risk_level in recommendations_by_risk:
            risk_emoji = {"Critical": "üö®", "High": "‚ö†Ô∏è", "Medium": "‚ö°", "Low": "‚ÑπÔ∏è"}
            markdown_summary.append(f"#### {risk_emoji[risk_level]} **Prioridade {risk_level}**")
            
            for category, recommendations in recommendations_by_risk[risk_level].items():
                markdown_summary.append(f"\n**{category}:**")
                for i, rec in enumerate(recommendations, 1):
                    markdown_summary.append(f"{i}. {rec}")
                markdown_summary.append("")
    
    return "\n".join(markdown_summary)

def render_enhanced_dashboards(result: AIAnalysisResult):
    """Renderiza dashboards visuais aprimorados e consolidados."""
    st.subheader("üìä Dashboards Inteligentes")
    
    # Seletor de persona para customizar visualiza√ß√£o
    persona = st.selectbox(
        "üéØ Selecione sua perspectiva:",
        ["üëî Executivo (C-Level)", "üõ°Ô∏è Analista de Seguran√ßa", "üìã Auditor/Compliance"],
        help="Personaliza os dashboards para sua fun√ß√£o"
    )
    
    viz_generator = SecurityVisualizationGenerator()
    
    if persona == "üëî Executivo (C-Level)":
        render_executive_focused_dashboard(result, viz_generator)
    elif persona == "üõ°Ô∏è Analista de Seguran√ßa":
        render_security_analyst_dashboard(result, viz_generator)
    else:  # Auditor/Compliance
        render_compliance_focused_dashboard(result, viz_generator)

def render_executive_focused_dashboard(result: AIAnalysisResult, viz_generator):
    """Dashboard otimizado para executivos - foco em KPIs e decis√µes estrat√©gicas."""
    st.markdown("### üëî Vis√£o Executiva - Governan√ßa Azure")
    
    # KPIs principais em cards
    col1, col2, col3, col4 = st.columns(4)
    
    risk_score = getattr(result.risk_assessment, 'score', 0)
    critical_findings = len([f for f in result.findings if f.risk_level.value == "Critical"])
    total_findings = len(result.findings)
    
    with col1:
        st.metric(
            "üéØ Score de Risco", 
            f"{risk_score}/100",
            delta=f"-{100-risk_score} vs. ideal" if risk_score < 100 else "‚úÖ Ideal"
        )
    
    with col2:
        st.metric(
            "üö® Achados Cr√≠ticos", 
            critical_findings,
            delta=f"{critical_findings} requer a√ß√£o imediata" if critical_findings > 0 else "‚úÖ Nenhum"
        )
    
    with col3:
        st.metric(
            "üìä Total de Achados", 
            total_findings,
            help="Inclui todos os n√≠veis de risco"
        )
    
    with col4:
        compliance_score = 100 - (critical_findings * 20 + (total_findings - critical_findings) * 5)
        compliance_score = max(0, min(100, compliance_score))
        st.metric(
            "üõ°Ô∏è Compliance", 
            f"{compliance_score}%",
            delta=f"Meta: 95%" if compliance_score < 95 else "‚úÖ Conforme"
        )
    
    # Gr√°fico executivo principal - mais limpo e focado
    st.markdown("#### üìà Resumo Executivo de Riscos")
    fig_exec = viz_generator.create_governance_dashboard(result)
    st.plotly_chart(fig_exec, width='stretch')
    
    # Top 3 riscos cr√≠ticos
    if result.findings:
        st.markdown("#### üö® Top 3 Riscos que Requerem Aten√ß√£o Executiva")
        critical_findings_sorted = sorted(
            [f for f in result.findings if f.risk_level.value in ["Critical", "High"]], 
            key=lambda x: (x.risk_level.value == "Critical", len(getattr(x, 'affected_principals', []))), 
            reverse=True
        )[:3]
        
        for i, finding in enumerate(critical_findings_sorted, 1):
            with st.expander(f"üéØ Risco #{i}: {finding.title}", expanded=i==1):
                col_desc, col_action = st.columns([2, 1])
                with col_desc:
                    st.write(f"**Impacto:** {getattr(finding, 'business_impact', 'Impact assessment needed')}")
                    st.write(f"**Usu√°rios afetados:** {len(getattr(finding, 'affected_principals', []))}")
                with col_action:
                    st.markdown(f"**A√ß√£o requerida:**\n{finding.recommendation}")

def render_security_analyst_dashboard(result: AIAnalysisResult, viz_generator):
    """Dashboard otimizado para analistas de seguran√ßa - foco em investiga√ß√£o e a√ß√£o."""
    st.markdown("### üõ°Ô∏è Centro de Opera√ß√µes de Seguran√ßa")
    
    # M√©tricas operacionais
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üéØ Distribui√ß√£o de Riscos")
        fig_dist = viz_generator.create_risk_distribution_chart(result)
        st.plotly_chart(fig_dist, width='stretch')
        
        st.markdown("#### üîç Achados por Categoria")
        fig_findings = viz_generator.create_findings_by_type_chart(result)
        st.plotly_chart(fig_findings, width='stretch')
        
    with col2:
        st.markdown("#### üë• Mapa de Usu√°rios de Risco")
        # Simula√ß√£o de heatmap de usu√°rios
        if result.findings:
            user_risk_data = {}
            for finding in result.findings:
                for user in getattr(finding, 'affected_principals', [])[:10]:  # Limita a 10
                    if user not in user_risk_data:
                        user_risk_data[user] = {"Critical": 0, "High": 0, "Medium": 0, "Low": 0}
                    user_risk_data[user][finding.risk_level.value] += 1
            
            if user_risk_data:
                users_df = pd.DataFrame.from_dict(user_risk_data, orient='index').fillna(0)
                st.dataframe(users_df, width='stretch', height=400)
        
        st.markdown("#### ‚è±Ô∏è Timeline de Detec√ß√µes")
        fig_timeline = viz_generator.create_timeline_chart(result)
        st.plotly_chart(fig_timeline, width='stretch')
    
    # Lista de a√ß√µes priorit√°rias
    st.markdown("#### üìã Fila de Remedia√ß√£o Priorit√°ria")
    if result.findings:
        priority_findings = sorted(result.findings, key=lambda x: (
            x.risk_level.value == "Critical",
            x.risk_level.value == "High", 
            len(getattr(x, 'affected_principals', []))
        ), reverse=True)
        
        for i, finding in enumerate(priority_findings[:5], 1):
            priority_icon = "üö®" if finding.risk_level.value == "Critical" else "‚ö†Ô∏è" if finding.risk_level.value == "High" else "‚ö°"
            st.markdown(f"**{i}. {priority_icon} {finding.title}**")
            st.markdown(f"   ‚Üí *A√ß√£o:* {finding.recommendation}")
            if i < len(priority_findings[:5]):
                st.markdown("---")

def render_compliance_focused_dashboard(result: AIAnalysisResult, viz_generator):
    """Dashboard otimizado para auditores - foco em evid√™ncias e conformidade."""
    st.markdown("### üìã Centro de Compliance e Auditoria")
    
    # Matriz de compliance
    st.markdown("#### üèõÔ∏è Matriz de Frameworks de Compliance")
    fig_matrix = viz_generator.create_compliance_matrix(result)
    st.plotly_chart(fig_matrix, width='stretch')
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä Status por Framework")
        # Simula√ß√£o de compliance por framework
        frameworks = ["SOX", "NIST", "ISO27001", "GDPR", "HIPAA", "PCI-DSS"]
        compliance_data = []
        
        for framework in frameworks:
            # Simula viola√ß√µes por framework
            violations = len([f for f in result.findings if hasattr(f, 'compliance_impact') and 
                            any(comp.value == framework for comp in getattr(f, 'compliance_impact', []))])
            compliance_score = max(0, 100 - violations * 15)
            status = "‚úÖ Conforme" if compliance_score >= 90 else "‚ö†Ô∏è Aten√ß√£o" if compliance_score >= 70 else "üö® Cr√≠tico"
            compliance_data.append({
                "Framework": framework,
                "Score": f"{compliance_score}%",
                "Status": status,
                "Viola√ß√µes": violations
            })
        
        compliance_df = pd.DataFrame(compliance_data)
        st.dataframe(compliance_df, width='stretch', hide_index=True)
    
    with col2:
        st.markdown("#### üîç Evid√™ncias Estruturadas")
        if result.findings:
            evidence_count = sum(1 for f in result.findings if hasattr(f, 'evidence') and getattr(f, 'evidence', {}))
            st.metric("Evid√™ncias Coletadas", evidence_count)
            st.metric("Achados Documentados", len(result.findings))
            st.metric("Requer Documenta√ß√£o Adicional", 
                     len([f for f in result.findings if not hasattr(f, 'evidence') or not getattr(f, 'evidence', {})]))
    
    # Relat√≥rio de auditoria
    st.markdown("#### üìÑ Resumo para Relat√≥rio de Auditoria")
    audit_summary = generate_audit_summary(result)
    st.markdown(audit_summary)

def generate_audit_summary(result: AIAnalysisResult) -> str:
    """Gera resumo estruturado para relat√≥rios de auditoria."""
    critical_count = len([f for f in result.findings if f.risk_level.value == "Critical"])
    high_count = len([f for f in result.findings if f.risk_level.value == "High"])
    total_count = len(result.findings)
    
    summary = f"""
**RESUMO EXECUTIVO DE AUDITORIA**

**Escopo:** An√°lise de governan√ßa de identidade e acesso Azure  
**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M')}  
**Achados totais:** {total_count}

**CLASSIFICA√á√ÉO DE RISCOS:**
- üö® **Cr√≠ticos:** {critical_count} (requer a√ß√£o imediata)
- ‚ö†Ô∏è **Altos:** {high_count} (requer a√ß√£o em 30 dias)
- ‚ö° **M√©dios/Baixos:** {total_count - critical_count - high_count}

**RECOMENDA√á√ÉO GERAL:**
{'üö® **A√á√ÉO IMEDIATA REQUERIDA** - Riscos cr√≠ticos identificados que podem impactar a conformidade regulat√≥ria.' if critical_count > 0 else 
 '‚ö†Ô∏è **MONITORAMENTO ATIVO** - Implementar a√ß√µes corretivas para riscos altos identificados.' if high_count > 0 else
 '‚úÖ **POSTURA ADEQUADA** - Manter monitoramento cont√≠nuo e implementar melhorias sugeridas.'}

**STATUS DE COMPLIANCE:** {'N√ÉO CONFORME' if critical_count > 0 else 'CONFORME COM OBSERVA√á√ïES' if high_count > 0 else 'CONFORME'}
"""
    return summary

def render_trends_and_predictions(enhanced_result: EnhancedAIAnalysisResult):
    """Dashboard de tend√™ncias e predi√ß√µes baseadas em IA."""
    st.markdown("### üìà An√°lise de Tend√™ncias e Predi√ß√µes")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìä Tend√™ncias Observadas")
        
        # Simula√ß√£o de dados de tend√™ncia
        trend_data = {
            "M√©trica": ["Viola√ß√µes SOD", "Atribui√ß√µes Diretas", "Contas √ìrf√£s", "Privilege Escalation"],
            "√öltimo M√™s": [5, 12, 3, 2],
            "Este M√™s": [3, 8, 1, 1],
            "Tend√™ncia": ["‚ÜòÔ∏è Melhorando", "‚ÜòÔ∏è Melhorando", "‚ÜòÔ∏è Melhorando", "‚Üí Est√°vel"]
        }
        trend_df = pd.DataFrame(trend_data)
        st.dataframe(trend_df, hide_index=True, width='stretch')
        
        st.markdown("#### üéØ Score de Melhoria")
        improvement_score = 85  # Simulado
        st.metric(
            "Progresso Geral", 
            f"{improvement_score}%", 
            delta=f"+15% vs. baseline",
            help="Baseado na redu√ß√£o de viola√ß√µes e implementa√ß√£o de controles"
        )
    
    with col2:
        st.markdown("#### üîÆ Predi√ß√µes IA")
        
        st.info("""
        **An√°lise Preditiva (30 dias):**
        
        üü¢ **Baixo Risco:** Continuar tend√™ncia de melhoria atual
        - Redu√ß√£o estimada de 20% em viola√ß√µes SOD
        - Implementa√ß√£o de controles preventivos funcionando
        
        ‚ö†Ô∏è **Aten√ß√£o:** Monitorar atribui√ß√µes diretas
        - Poss√≠vel aumento se n√£o implementar processo de aprova√ß√£o
        
        üéØ **Recomenda√ß√£o:** Manter cad√™ncia atual de remedia√ß√£o
        """)
        
        st.markdown("#### üìÖ Pr√≥ximas Revis√µes Sugeridas")
        next_reviews = [
            {"Data": "30/09/2025", "Tipo": "Review SOD", "Prioridade": "Alta"},
            {"Data": "15/10/2025", "Tipo": "Auditoria Compliance", "Prioridade": "M√©dia"},
            {"Data": "01/11/2025", "Tipo": "Assessment Completo", "Prioridade": "Alta"}
        ]
        reviews_df = pd.DataFrame(next_reviews)
        st.dataframe(reviews_df, hide_index=True, width='stretch')

def render_action_center(enhanced_result: EnhancedAIAnalysisResult):
    """Centro de a√ß√µes priorizadas com tracking de progresso."""
    st.markdown("### üéØ Centro de A√ß√µes Priorit√°rias")
    
    # Filtros para a√ß√µes
    col1, col2, col3 = st.columns(3)
    
    with col1:
        priority_filter = st.selectbox(
            "Filtrar por Prioridade:",
            ["Todas", "Cr√≠tica", "Alta", "M√©dia", "Baixa"]
        )
    
    with col2:
        status_filter = st.selectbox(
            "Status:",
            ["Todas", "Pendente", "Em Andamento", "Conclu√≠da"]
        )
    
    with col3:
        assignee_filter = st.selectbox(
            "Respons√°vel:",
            ["Todos", "Equipe de Seguran√ßa", "Equipe de Identidade", "Compliance", "Gest√£o"]
        )
    
    # Simula√ß√£o de lista de a√ß√µes
    actions_data = []
    
    # Mapeia as prioridades do ingl√™s para portugu√™s
    priority_map = {
        "Critical": "Cr√≠tica",
        "High": "Alta", 
        "Medium": "M√©dia",
        "Low": "Baixa"
    }

    def get_status_for_finding(finding: DetailedFinding, index: int) -> str:
        """Determina o status da a√ß√£o baseado em crit√©rios consistentes."""
        if finding.risk_level == RiskLevel.CRITICAL:
            return "Pendente"  # Cr√≠tico sempre come√ßa como pendente
        elif finding.risk_level == RiskLevel.HIGH:
            return "Em Andamento"
        else:
            return "Pendente" if index <= 5 else "Conclu√≠da"

    def get_assignee_for_finding(finding: DetailedFinding) -> str:
        """Determina o respons√°vel baseado no tipo de viola√ß√£o."""
        violation_assignee_map = {
            GovernanceViolationType.SOD_VIOLATION: "Equipe de Seguran√ßa",
            GovernanceViolationType.COMPLIANCE_VIOLATION: "Compliance",
            GovernanceViolationType.EXCESSIVE_PRIVILEGES: "Equipe de Identidade",
            GovernanceViolationType.DIRECT_ASSIGNMENT: "Equipe de Identidade",
            GovernanceViolationType.SUSPICIOUS_ACCESS: "Equipe de Seguran√ßa",
            GovernanceViolationType.DUPLICATE_GROUPS: "Gest√£o",
            GovernanceViolationType.ORPHANED_ACCOUNTS: "Equipe de Identidade",
            GovernanceViolationType.PRIVILEGE_ESCALATION: "Equipe de Seguran√ßa"
        }
        return violation_assignee_map.get(finding.violation_type, "Gest√£o")

    for i, finding in enumerate(enhanced_result.findings[:10], 1):
        priority_level = priority_map[finding.risk_level.value]
        action_id = f"ACT-{i:03d}"
        
        # Determina status e respons√°vel de forma consistente
        status = get_status_for_finding(finding, i)
        assignee = get_assignee_for_finding(finding)
        
        # Estimativa de tempo baseada na prioridade
        time_estimates = {
            "Cr√≠tica": "24h",
            "Alta": "3 dias", 
            "M√©dia": "1 semana", 
            "Baixa": "2 semanas"
        }
        
        actions_data.append({
            "ID": action_id,
            "A√ß√£o": finding.recommendation[:80] + "..." if len(finding.recommendation) > 80 else finding.recommendation,
            "Prioridade": priority_level,
            "Status": status,
            "Respons√°vel": assignee,
            "Prazo Est.": time_estimates.get(priority_level, "1 semana"),
            "Impacto": f"{len(getattr(finding, 'affected_principals', []))} usu√°rios"
        })
    
    # Aplica filtros
    filtered_actions = actions_data
    if priority_filter != "Todas":
        filtered_actions = [a for a in filtered_actions if a["Prioridade"] == priority_filter]
    if status_filter != "Todas":
        filtered_actions = [a for a in filtered_actions if a["Status"] == status_filter]
    if assignee_filter != "Todos":
        filtered_actions = [a for a in filtered_actions if a["Respons√°vel"] == assignee_filter]
    
    # Exibe lista de a√ß√µes
    st.markdown("#### üìã Lista de A√ß√µes")
    if filtered_actions:
        actions_df = pd.DataFrame(filtered_actions)
        st.dataframe(actions_df, hide_index=True, width='stretch', height=400)
        
        # Estat√≠sticas das a√ß√µes
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            pending_count = len([a for a in filtered_actions if a["Status"] == "Pendente"])
            st.metric("Pendentes", pending_count)
        
        with col2:
            progress_count = len([a for a in filtered_actions if a["Status"] == "Em Andamento"])
            st.metric("Em Andamento", progress_count)
        
        with col3:
            completed_count = len([a for a in filtered_actions if a["Status"] == "Conclu√≠da"])
            st.metric("Conclu√≠das", completed_count)
        
        with col4:
            completion_rate = (completed_count / len(filtered_actions) * 100) if filtered_actions else 0
            st.metric("Taxa de Conclus√£o", f"{completion_rate:.1f}%")
        
        # Bot√µes de a√ß√£o
        st.markdown("#### ‚ö° A√ß√µes R√°pidas")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìä Exportar Plano de A√ß√£o", key="export_action_plan"):
                st.success("Plano de a√ß√£o exportado!")
        
        with col2:
            if st.button("üìß Enviar Notifica√ß√µes", key="send_notifications"):
                st.success("Notifica√ß√µes enviadas aos respons√°veis!")
        
        with col3:
            if st.button("üìà Gerar Relat√≥rio de Progresso", key="progress_report"):
                st.success("Relat√≥rio de progresso gerado!")
    
    else:
        st.info("Nenhuma a√ß√£o encontrada com os filtros selecionados.")

def export_report_to_json(analysis_result, governance_summary):
    """Exporta relat√≥rio completo para JSON."""
    report_data = {
        "export_timestamp": datetime.now().isoformat(),
        "governance_summary": governance_summary,
        "ai_analysis": analysis_result.model_dump() if analysis_result else None,
        "report_metadata": {
            "version": "2.0",
            "tool": "PrivIQ",
            "export_format": "comprehensive"
        }
    }
    return json.dumps(report_data, indent=2, default=str)

def render_enhanced_analysis_report(enhanced_result: EnhancedAIAnalysisResult):
    """Renderiza relat√≥rio de an√°lise avan√ßada com detalhes expandidos."""
    st.subheader("üîç An√°lise Avan√ßada de Governan√ßa")
    
    # Resumo executivo
    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("### üìã Resumo Executivo")
        st.info(enhanced_result.executive_summary)
        
        st.markdown("### üîß Resumo T√©cnico")
        st.warning(enhanced_result.technical_summary)
    
    with col2:
        # M√©tricas principais
        governance_metrics = enhanced_result.risk_assessment.governance_metrics
        st.metric("Score de Risco", f"{enhanced_result.risk_assessment.score}/100")
        st.metric("Score de Compliance", f"{governance_metrics.compliance_score:.1f}%")
        st.metric("Viola√ß√µes SOD", governance_metrics.sod_violations)
        st.metric("Atribui√ß√µes Diretas", governance_metrics.direct_assignments)
    
    # Achados detalhados por tipo
    if enhanced_result.findings:
        st.markdown("### üéØ Achados Detalhados por Categoria")
        
        # Agrupa achados por tipo de viola√ß√£o
        findings_by_type = defaultdict(list)
        for finding in enhanced_result.findings:
            findings_by_type[finding.violation_type.value].append(finding)
        
        for violation_type, findings in findings_by_type.items():
            type_name = violation_type.replace('_', ' ').title()
            
            with st.expander(f"üö® {type_name} ({len(findings)} achados)", expanded=len(findings) <= 3):
                for finding in findings:
                    render_detailed_finding(finding)
    
    # Pr√≥ximas a√ß√µes
    if enhanced_result.next_actions:
        st.markdown("### üìã Pr√≥ximas A√ß√µes Recomendadas")
        for i, action in enumerate(enhanced_result.next_actions, 1):
            st.markdown(f"**{i}.** {action}")

def render_detailed_finding(finding: DetailedFinding):
    """Renderiza um achado detalhado."""
    risk_color = {
        "Critical": "#8B0000",
        "High": "#DC143C", 
        "Medium": "#FF8C00",
        "Low": "#228B22"
    }.get(finding.risk_level.value, "#4682B4")
    
    st.markdown(f"""
    <div style="border-left: 4px solid {risk_color}; padding: 1rem; margin: 1rem 0; background-color: #f8f9fa; border-radius: 5px;">
        <h4 style="color: {risk_color}; margin: 0 0 0.5rem 0;">{finding.title}</h4>
        <p><strong>Tipo:</strong> {finding.violation_type.value.replace('_', ' ')}</p>
        <p><strong>Prioridade de Remedia√ß√£o:</strong> {finding.remediation_priority}/5</p>
    </div>
    """, unsafe_allow_html=True)
    
    with st.expander("Ver detalhes completos", expanded=False):
        st.markdown("**üìù Descri√ß√£o:**")
        st.write(finding.description)
        
        st.markdown("**üîß Recomenda√ß√£o:**")
        st.success(finding.recommendation)
        
        if finding.business_impact:
            st.markdown("**üíº Impacto no Neg√≥cio:**")
            st.warning(finding.business_impact)
        
        if finding.compliance_impact:
            st.markdown("**üìä Frameworks de Compliance Afetados:**")
            for framework in finding.compliance_impact:
                st.markdown(f"- {framework.value}")
        
        if finding.evidence:
            st.markdown("**üîç Evid√™ncias:**")
            st.json(finding.evidence)
        
        if finding.affected_principals:
            st.markdown("**üë• Principais Afetados:**")
            principals_to_show = finding.affected_principals[:10]
            for principal in principals_to_show:
                st.markdown(f"- `{principal}`")
            
            if len(finding.affected_principals) > 10:
                st.markdown(f"*... e mais {len(finding.affected_principals) - 10} principais*")

def render_executive_dashboard(enhanced_result: EnhancedAIAnalysisResult):
    """Renderiza dashboard executivo com visualiza√ß√µes avan√ßadas."""
    st.subheader("üìä Dashboard Executivo")
    
    # Cria gerador de visualiza√ß√µes
    viz_generator = SecurityVisualizationGenerator()
    
    # Dashboard principal
    fig_dashboard = viz_generator.create_executive_dashboard(enhanced_result)
    st.plotly_chart(fig_dashboard, width='stretch')
    
    # Gr√°ficos espec√≠ficos
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üéØ Distribui√ß√£o de Viola√ß√µes")
        fig_violations = viz_generator.create_governance_violations_chart(enhanced_result.findings)
        st.plotly_chart(fig_violations, width='stretch')
    
    with col2:
        st.markdown("#### üë• Mapa de Risco por Usu√°rio")
        fig_heatmap = viz_generator.create_user_risk_heatmap(enhanced_result.findings)
        st.plotly_chart(fig_heatmap, width='stretch')
    
    # Timeline de detec√ß√µes
    st.markdown("#### ‚è±Ô∏è Timeline de Detec√ß√µes")
    fig_timeline = viz_generator.create_timeline_analysis(enhanced_result.findings)
    st.plotly_chart(fig_timeline, width='stretch')

def render_compliance_analysis(enhanced_result: EnhancedAIAnalysisResult):
    """Renderiza an√°lise espec√≠fica de compliance."""
    st.subheader("üõ°Ô∏è An√°lise de Compliance e Frameworks")
    
    # Gr√°fico de compliance
    viz_generator = SecurityVisualizationGenerator()
    fig_compliance = viz_generator.create_compliance_framework_chart(enhanced_result.findings)
    st.plotly_chart(fig_compliance, width='stretch')
    
    # Assessment de compliance
    if hasattr(enhanced_result.risk_assessment, 'compliance_assessment') and enhanced_result.risk_assessment.compliance_assessment:
        compliance_assessment = enhanced_result.risk_assessment.compliance_assessment
        
        st.markdown("### üìã Assessment de Compliance")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Score Geral de Compliance", f"{compliance_assessment.overall_score:.1f}%")
        
        with col2:
            framework_scores = compliance_assessment.framework_scores
            if framework_scores:
                avg_score = sum(framework_scores.values()) / len(framework_scores)
                st.metric("Score M√©dio por Framework", f"{avg_score:.1f}%")
        
        # Scores por framework
        if framework_scores:
            st.markdown("#### üìä Scores por Framework")
            for framework, score in framework_scores.items():
                progress_color = "green" if score >= 80 else "orange" if score >= 60 else "red"
                st.markdown(f"**{framework}**")
                st.progress(score/100, text=f"{score:.1f}%")
        
        # Lacunas cr√≠ticas
        critical_gaps = compliance_assessment.critical_gaps
        if critical_gaps:
            st.markdown("#### üö® Lacunas Cr√≠ticas")
            for gap in critical_gaps[:5]:
                st.error(f"‚Ä¢ {gap}")

def render_forensic_analysis(enhanced_result: EnhancedAIAnalysisResult):
    """Renderiza an√°lise forense detalhada."""
    st.subheader("üîç An√°lise Forense")
    
    # Metadados da an√°lise
    metadata = enhanced_result.analysis_metadata
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Logs Analisados", metadata.get('total_logs_analyzed', 0))
    with col2:
        st.metric("Achados Cr√≠ticos", metadata.get('critical_findings', 0))
    with col3:
        st.metric("Achados de Alto Risco", metadata.get('high_findings', 0))
    
    # An√°lise temporal
    if metadata.get('analysis_timestamp'):
        st.info(f"üìÖ An√°lise executada em: {metadata['analysis_timestamp']}")
    
    # Correla√ß√£o de eventos
    st.markdown("### üîó Correla√ß√£o de Eventos")
    
    # Agrupa achados por usu√°rios afetados para detectar padr√µes
    user_involvement = defaultdict(list)
    for finding in enhanced_result.findings:
        for user in finding.affected_principals:
            user_involvement[user].append(finding.violation_type.value)
    
    # Usu√°rios com m√∫ltiplas viola√ß√µes
    multi_violation_users = {user: violations for user, violations in user_involvement.items() if len(set(violations)) > 1}
    
    if multi_violation_users:
        st.warning("üö® **Usu√°rios com M√∫ltiplas Viola√ß√µes (Padr√£o Suspeito):**")
        for user, violations in list(multi_violation_users.items())[:10]:
            unique_violations = list(set(violations))
            st.markdown(f"- **{user}**: {', '.join(unique_violations)}")
    
    # Padr√µes de escala√ß√£o
    escalation_findings = [f for f in enhanced_result.findings if f.violation_type.value == 'Privilege_Escalation']
    if escalation_findings:
        st.markdown("### ‚¨ÜÔ∏è Padr√µes de Escala√ß√£o de Privil√©gios")
        for finding in escalation_findings:
            st.error(f"üî∫ {finding.title} - {len(finding.affected_principals)} usu√°rios afetados")

def render_enhanced_export_options(enhanced_result: EnhancedAIAnalysisResult):
    """Renderiza op√ß√µes de exporta√ß√£o aprimoradas."""
    st.subheader("üì§ Exporta√ß√£o de Relat√≥rios")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìã Relat√≥rios Executivos")
        
        if st.button("üìä Relat√≥rio Executivo (JSON)", width='stretch', key="executive_json"):
            executive_report = {
                "executive_summary": enhanced_result.executive_summary,
                "risk_score": enhanced_result.risk_assessment.score,
                "compliance_score": enhanced_result.risk_assessment.governance_metrics.compliance_score,
                "next_actions": enhanced_result.next_actions,
                "critical_findings": [f.title for f in enhanced_result.findings if f.risk_level.value == "Critical"],
                "timestamp": enhanced_result.analysis_metadata.get('analysis_timestamp')
            }
            
            st.download_button(
                label="üíæ Download Relat√≥rio Executivo",
                data=json.dumps(executive_report, indent=2),
                file_name=f"executive_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                width='stretch'
            )
        
        if st.button("üìã Relat√≥rio T√©cnico (JSON)", width='stretch', key="technical_json"):
            technical_report = {
                "technical_summary": enhanced_result.technical_summary,
                "detailed_findings": [
                    {
                        "title": f.title,
                        "violation_type": f.violation_type.value,
                        "risk_level": f.risk_level.value,
                        "description": f.description,
                        "recommendation": f.recommendation,
                        "evidence": f.evidence,
                        "affected_principals": f.affected_principals,
                        "compliance_impact": [cf.value for cf in f.compliance_impact],
                        "remediation_priority": f.remediation_priority
                    }
                    for f in enhanced_result.findings
                ],
                "governance_metrics": enhanced_result.risk_assessment.governance_metrics,
                "analysis_metadata": enhanced_result.analysis_metadata
            }
            
            st.download_button(
                label="üíæ Download Relat√≥rio T√©cnico",
                data=json.dumps(technical_report, indent=2, default=str),
                file_name=f"technical_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                width='stretch'
            )
    
    with col2:
        st.markdown("#### üìä Relat√≥rios Tabulares")
        
        if st.button("üìà Planilha de Achados (CSV)", width='stretch', key="findings_csv"):
            if enhanced_result.findings:
                findings_df = pd.DataFrame([
                    {
                        'Tipo_Violacao': f.violation_type.value,
                        'Nivel_Risco': f.risk_level.value,
                        'Titulo': f.title,
                        'Descricao': f.description,
                        'Recomendacao': f.recommendation,
                        'Prioridade_Remediacao': f.remediation_priority,
                        'Impacto_Negocio': f.business_impact,
                        'Frameworks_Compliance': ';'.join([cf.value for cf in f.compliance_impact]),
                        'Quantidade_Afetados': len(f.affected_principals),
                        'Principais_Afetados': ';'.join(f.affected_principals[:10]),
                        'Timestamp_Deteccao': f.detection_timestamp
                    }
                    for f in enhanced_result.findings
                ])
                
                csv_data = findings_df.to_csv(index=False)
                st.download_button(
                    label="üíæ Download Planilha CSV",
                    data=csv_data,
                    file_name=f"governance_findings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    width='stretch'
                )
        
        if st.button("üìã Relat√≥rio Compliance (CSV)", width='stretch', key="compliance_csv"):
            # Cria relat√≥rio espec√≠fico de compliance
            compliance_data = []
            for finding in enhanced_result.findings:
                for framework in finding.compliance_impact:
                    compliance_data.append({
                        'Framework': framework.value,
                        'Violacao': finding.title,
                        'Nivel_Risco': finding.risk_level.value,
                        'Quantidade_Afetados': len(finding.affected_principals),
                        'Prioridade': finding.remediation_priority
                    })
            
            if compliance_data:
                compliance_df = pd.DataFrame(compliance_data)
                csv_data = compliance_df.to_csv(index=False)
                st.download_button(
                    label="üíæ Download Relat√≥rio Compliance",
                    data=csv_data,
                    file_name=f"compliance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    width='stretch'
                )

def render_export_options(analysis_result: AIAnalysisResult):
    """Renderiza op√ß√µes de exporta√ß√£o para an√°lise padr√£o."""
    st.subheader("üì§ Exporta√ß√£o de Relat√≥rio")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üìã Gerar Relat√≥rio JSON", width='stretch', key="json_report_standard"):
            report_json = export_report_to_json(analysis_result, st.session_state.governance_summary)
            st.download_button(
                label="üíæ Download Relat√≥rio JSON",
                data=report_json,
                file_name=f"azure_governance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                width='stretch'
            )
    
    with col2:
        if st.button("üìä Gerar Relat√≥rio CSV", width='stretch', key="csv_report_standard"):
            if analysis_result.findings:
                findings_df = pd.DataFrame([
                    {
                        'Risk Level': f.risk_level.value,
                        'Title': f.title,
                        'Description': f.description,
                        'Recommendation': f.recommendation,
                        'Affected Count': len(f.affected_principals),
                        'Affected Principals': '; '.join(f.affected_principals[:5])
                    }
                    for f in analysis_result.findings
                ])
                
                csv_data = findings_df.to_csv(index=False)
                st.download_button(
                    label="üíæ Download CSV",
                    data=csv_data,
                    file_name=f"findings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    width='stretch'
                )

def main():
    """Fun√ß√£o principal da aplica√ß√£o aprimorada."""
    try:
        initialize_session_state()
        
        st.markdown('<h1 class="main-header">üõ°Ô∏è PrivIQ</h1>', unsafe_allow_html=True)
        st.markdown('<p style="text-align: center; color: #666; font-size: 1.2rem;">An√°lise Inteligente de Governan√ßa e Compliance para Microsoft Azure</p>', unsafe_allow_html=True)
        
        # Verifica√ß√£o se o processador foi inicializado corretamente
        if st.session_state.processor is None:
            st.session_state.processor = AzureLogProcessor()
        
        # Barra lateral aprimorada
        with st.sidebar:
            st.header("‚öôÔ∏è Configura√ß√£o")
            
            # Se√ß√£o de informa√ß√µes sobre o sistema
            with st.expander("‚ÑπÔ∏è Sobre o Sistema"):
                st.markdown("""
                Este sistema analisa logs de governan√ßa do Azure para identificar:
                - üö´ Viola√ß√µes SOD (Segrega√ß√£o de Fun√ß√µes)
                - üë§ Atribui√ß√µes diretas de acesso
                - üíÄ Contas √≥rf√£s e privilegiadas
                - üìà Padr√µes de escala√ß√£o de privil√©gios
                """)
            
            with st.expander("üìã Formatos de Logs Suportados"):
                st.markdown("""
                **Formato 1: Role Assignments (Preferido)**
                ```json
                [{
                    "SignInName": "user@domain.com",
                    "DisplayName": "User Name",
                    "RoleDefinitionName": "Global Administrator",
                    "ObjectType": "User"
                }]
                ```
                
                **Formato 2: Activity Logs**
                ```json
                [{
                    "user_principal_name": "user@domain.com",
                    "display_name": "User Name", 
                    "role_name": "Global Administrator"
                }]
                ```
                """)
            
            with st.expander("üöÄ Como usar"):
                st.markdown("""
                1. **Upload:** Fa√ßa upload do arquivo JSON de logs
                2. **An√°lise:** Escolha entre an√°lise padr√£o ou avan√ßada (com IA)
                3. **Relat√≥rios:** Visualize os resultados nas abas correspondentes
                4. **Dashboard:** Acesse o painel executivo para vis√£o geral
                """)
            
            st.divider()
            st.subheader("üîå Status das Conex√µes")
            
            try:
                openai_configured = config.is_openai_configured()
            except Exception as e:
                openai_configured = False
                st.warning(f"Erro ao verificar configura√ß√£o OpenAI: {e}")
            
            openai_status = "‚úÖ Conectado" if openai_configured else "‚ùå N√£o Configurado"
            st.markdown(f"**Azure OpenAI:** {openai_status}")
            
            if not openai_configured:
                with st.expander("üîß Configurar Azure OpenAI"):
                    st.warning("Configure a API Key no arquivo config.py:")
                    st.code("""
# No config.py, defina:
config.openai_api_key = "sua_chave_api_key_aqui"
                    """)
            
            st.divider()
            st.subheader("‚òÅÔ∏è Azure Data Sources")
            
            # Renderiza a interface aprimorada para fontes de dados Azure
            render_enhanced_data_interface()
            
            st.divider()
            st.subheader("üìä Par√¢metros de An√°lise")
            max_logs_to_analyze = st.slider(
                "M√°ximo de Logs para An√°lise IA", 
                min_value=50, max_value=2000, value=500, step=50,
                help="Limite de logs enviados para an√°lise da IA (para otimizar custos)"
            )
            
            enable_detailed_analysis = st.checkbox(
                "An√°lise Detalhada de Governan√ßa", 
                value=True,
                help="Executa an√°lise completa de padr√µes de governan√ßa"
            )
            
            st.divider()
            st.markdown("### üìã Funcionalidades")
            st.markdown("‚úÖ Detec√ß√£o de Viola√ß√µes SOD")
            st.markdown("‚úÖ Atribui√ß√µes Diretas de Roles")
            st.markdown("‚úÖ Permiss√µes Duplicadas")
            st.markdown("‚úÖ Padr√µes Suspeitos")
            st.markdown("‚úÖ An√°lise com IA")
            st.markdown("‚úÖ Dashboards Interativos")

        # Conte√∫do principal
        st.markdown("---")
        st.subheader("1Ô∏è‚É£ Fonte de Dados")
        
        # Op√ß√£o de escolha da fonte de dados
        data_source_option = st.radio(
            "Escolha a fonte dos dados:",
            ["üìÅ Upload de Arquivo", "‚òÅÔ∏è Azure Log Analytics", "üíæ Azure Blob Storage"],
            help="Selecione como deseja carregar os dados para an√°lise"
        )
        
        uploaded_file = None
        
        if data_source_option == "üìÅ Upload de Arquivo":
            uploaded_file = st.file_uploader(
                "üìÅ Selecione o arquivo de logs (JSON)",
                type=['json'], 
                help="Fa√ßa upload do arquivo de logs de auditoria do Azure ou Entra ID"
            )
        
        elif data_source_option in ["‚òÅÔ∏è Azure Log Analytics", "üíæ Azure Blob Storage"]:
            # Extrai o nome do servi√ßo de forma segura
            service_name = data_source_option.replace("‚òÅÔ∏è ", "").replace("üíæ ", "").strip()
            st.info(f"üìä Configurando conex√£o com {service_name}")
            
            # Renderiza interface Azure espec√≠fica
            with st.container():
                try:
                    # Chama a interface Azure que foi adicionada na sidebar
                    st.write("üí° **Dica:** Use a se√ß√£o 'Azure Data Sources' na barra lateral para configurar e buscar dados.")
                    
                    # Verifica se h√° dados Azure j√° carregados na sess√£o
                    if 'fetched_data' in st.session_state and st.session_state.fetched_data:
                        azure_data = st.session_state.fetched_data
                        st.success(f"‚úÖ Dados Azure carregados: {len(azure_data)} registros prontos para an√°lise!")
                        
                        # Simula uploaded_file para continuar o fluxo normal
                        uploaded_file = "azure_data"
                        
                        # Armazena os dados para processamento
                        st.session_state.azure_logs_data = azure_data
                        st.session_state.azure_data_loaded = True
                        
                        # Mostra preview dos dados
                        with st.expander("üìã Preview dos Dados Azure", expanded=False):
                            if azure_data:
                                preview_df = pd.DataFrame(azure_data[:5])  # Primeiros 5 registros
                                st.dataframe(preview_df, width='stretch')
                                st.info(f"Mostrando 5 de {len(azure_data)} registros carregados")
                    else:
                        st.warning("‚ö†Ô∏è Nenhum dado Azure encontrado. Use a interface Azure Data Sources na sidebar.")
                        st.info("üëà **Como usar:**\n1. Acesse 'Azure Data Sources' na barra lateral\n2. Configure suas credenciais\n3. Clique em 'Buscar Dados'\n4. Retorne aqui para iniciar a an√°lise")
                        
                        # Bot√£o para facilitar o acesso direto √† interface Azure
                        if st.button("üîß Configurar Azure Data Sources", type="secondary"):
                            st.info("üëà Acesse a se√ß√£o 'Azure Data Sources' na barra lateral para configurar suas conex√µes Azure.")
                        
                except Exception as e:
                    st.error(f"‚ùå Erro ao configurar interface Azure: {e}")
        
        # Se√ß√£o adicional para facilitar configura√ß√£o Azure quando n√£o h√° dados
        if data_source_option in ["‚òÅÔ∏è Azure Log Analytics", "üíæ Azure Blob Storage"] and uploaded_file != "azure_data":
            st.markdown("---")
            st.subheader("üîß Configura√ß√£o R√°pida Azure")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("""
                **Para usar dados diretos do Azure:**
                1. üëà Acesse **'Azure Data Sources'** na barra lateral
                2. ‚öôÔ∏è Configure suas credenciais (j√° est√£o no .env)
                3. üîç Teste a conex√£o
                4. üöÄ Clique em 'Buscar Dados'
                5. üîÑ Retorne aqui - os dados aparecer√£o automaticamente
                """)
            
            with col2:
                if st.button("üìä Ver Status Conex√µes", key="check_azure_status"):
                    # Verifica status das conex√µes Azure
                    try:
                        import os
                        from dotenv import load_dotenv
                        load_dotenv()
                        
                        workspace_id = os.getenv('AZURE_LOG_ANALYTICS_WORKSPACE_ID')
                        storage_account = os.getenv('AZURE_STORAGE_ACCOUNT')
                        
                        st.success("‚úÖ **Credenciais Azure Detectadas:**")
                        if workspace_id:
                            st.write(f"üìä Log Analytics: {workspace_id[:8]}...")
                        if storage_account:
                            st.write(f"üíæ Storage Account: {storage_account}")
                            
                    except Exception as e:
                        st.error(f"Erro ao verificar credenciais: {e}")
        
        # Informa√ß√µes sobre formatos suportados
        with st.expander("üìã Formatos de Logs Suportados", expanded=False):
            st.markdown("""
            **O sistema suporta m√∫ltiplos formatos de logs Azure:**
            
            **1. Role Assignments (Atribui√ß√µes de Fun√ß√µes):**
            ```json
            {
                "RoleAssignmentId": "...",
                "DisplayName": "Nome do usu√°rio/grupo",
                "SignInName": "email@domain.com",
                "RoleDefinitionName": "Contribuidor",
                "ObjectType": "User" ou "Group",
                "Scope": "/subscriptions/..."
            }
            ```
            
            **2. Activity Logs (Logs de Atividade):**
            ```json
            {
                "operationName": "Add role assignment",
                "identity_userPrincipalName": "user@domain.com",
                "activityDateTime": "2024-09-22T10:00:00Z",
                "properties_roleName": "Global Administrator"
            }
            ```
            
            **3. Entra ID Audit Logs:**
            ```json
            {
                "callerIpAddress": "192.168.1.1",
                "operationName": "Add member to role",
                "resultType": "Success"
            }
            ```
            """)
        
        if uploaded_file:
            try:
                with st.spinner("üîÑ Processando dados..."):
                    # Diferencia entre upload de arquivo e dados Azure
                    if uploaded_file == "azure_data":
                        # Carrega dados que foram buscados do Azure via interface
                        if 'azure_logs_data' in st.session_state:
                            # Converte dados Azure para DataFrame
                            azure_data = st.session_state.azure_logs_data
                            st.session_state.logs_df = pd.DataFrame(azure_data)
                            st.success(f"‚úÖ Dados Azure carregados! {len(st.session_state.logs_df)} eventos processados.")
                        else:
                            st.warning("‚ö†Ô∏è Nenhum dado Azure encontrado. Use a interface Azure Data Sources na sidebar.")
                            st.session_state.logs_df = None
                    else:
                        # Processamento normal de arquivo
                        file_bytes = uploaded_file.getvalue()
                        try:
                            file_content = file_bytes.decode("utf-8")
                        except UnicodeDecodeError:
                            file_content = file_bytes.decode("latin-1")
                        
                        # Processa logs
                        st.session_state.logs_df = st.session_state.processor.load_logs_from_file(file_content)
                        st.success(f"‚úÖ Arquivo processado com sucesso! {len(st.session_state.logs_df)} eventos carregados.")
                    
                    # Gera resumo de governan√ßa se dados foram carregados
                    if st.session_state.logs_df is not None and len(st.session_state.logs_df) > 0:
                        if enable_detailed_analysis:
                            st.session_state.governance_summary = st.session_state.processor.generate_comprehensive_summary()
                        
                        # Mostra estat√≠sticas b√°sicas
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Total de Eventos", len(st.session_state.logs_df))
                        with col2:
                            unique_users = st.session_state.logs_df.get('user_principal_name', pd.Series()).nunique()
                            st.metric("Usu√°rios √önicos", unique_users)
                        with col3:
                            role_events = len(st.session_state.processor.role_assignments_df) if st.session_state.processor.role_assignments_df is not None else 0
                            st.metric("Eventos de Roles", role_events)
                    
            except Exception as e:
                st.error(f"‚ùå Erro ao processar arquivo: {str(e)}")
                
                # Diagn√≥stico mais detalhado do erro
                if 'user_principal_name' in str(e):
                    st.error("**Problema:** O arquivo n√£o cont√©m os campos esperados.")
                    st.info("""
                    **Solu√ß√£o:** Verifique se o arquivo cont√©m:
                    - `SignInName` ou `user_principal_name` para identificar usu√°rios
                    - `RoleDefinitionName` ou `role_name` para as fun√ß√µes
                    - `ObjectType` para distinguir usu√°rios de grupos
                    """)
                elif 'JSON' in str(e) or 'json' in str(e):
                    st.error("**Problema:** Formato JSON inv√°lido.")
                    st.info("""
                    **Solu√ß√£o:** 
                    1. Verifique se o arquivo √© um JSON v√°lido
                    2. Certifique-se de que √© um array de objetos: `[{...}, {...}]`
                    3. Teste o JSON em um validador online
                    """)
                else:
                    st.error("Verifique se o arquivo est√° no formato correto e tente novamente.")
                
                with st.expander("üîç Detalhes t√©cnicos do erro"):
                    st.code(str(e))
                    st.markdown("**Dica:** Consulte a se√ß√£o 'Formatos de Logs Suportados' acima para verificar se seu arquivo est√° no formato correto.")

        # An√°lise de Governan√ßa
        if st.session_state.logs_df is not None and enable_detailed_analysis:
            st.markdown("---")
            st.subheader("2Ô∏è‚É£ An√°lise de Governan√ßa")
            
            if st.session_state.governance_summary:
                render_governance_overview(st.session_state.governance_summary)
                
                # Relat√≥rios detalhados
                with st.expander("üìä Ver Relat√≥rios Detalhados de Governan√ßa", expanded=False):
                    render_detailed_governance_reports(st.session_state.governance_summary)

        # An√°lise com IA
        if st.session_state.logs_df is not None:
            st.markdown("---")
            st.subheader("3Ô∏è‚É£ An√°lise Inteligente com Azure OpenAI")
            
            # Seletor de modo de an√°lise
            analysis_mode = st.selectbox(
                "Modo de An√°lise",
                ["An√°lise Padr√£o", "An√°lise Avan√ßada de Governan√ßa"],
                help="An√°lise Avan√ßada inclui detec√ß√£o de padr√µes complexos e an√°lise forense"
            )
            
            if st.button("üöÄ Executar An√°lise de IA", type="primary", width='stretch', key="ai_analysis"):
                if not openai_configured:
                    st.error("‚ùå Configure o Azure OpenAI antes de executar a an√°lise.")
                    st.stop()
                    
                with st.spinner("ü§ñ Executando an√°lise inteligente... Isso pode levar alguns minutos."):
                    try:
                        logs_sample = st.session_state.logs_df.head(max_logs_to_analyze).to_dict(orient='records')
                        
                        if analysis_mode == "An√°lise Avan√ßada de Governan√ßa":
                            # Usa o novo analisador avan√ßado
                            advanced_analyzer = AdvancedGovernanceAnalyzer()
                            st.session_state.enhanced_analysis_result = advanced_analyzer.perform_comprehensive_analysis(logs_sample)
                            st.session_state.analysis_result = None  # Para usar s√≥ o resultado avan√ßado
                            st.success("‚úÖ An√°lise Avan√ßada de Governan√ßa conclu√≠da!")
                        else:
                            # Usa o analisador padr√£o
                            analyzer = AzureLogAnalyzer()
                            st.session_state.analysis_result = analyzer.analyze_security_patterns(logs_sample)
                            st.session_state.enhanced_analysis_result = None
                            st.success("‚úÖ An√°lise de IA conclu√≠da!")
                            
                    except Exception as e:
                        st.error(f"‚ùå Erro na an√°lise de IA: {str(e)}")
                        st.error("Verifique os logs da aplica√ß√£o para mais detalhes.")
                st.rerun()

        # Resultados da An√°lise
        if st.session_state.analysis_result or st.session_state.enhanced_analysis_result:
            st.markdown("---")
            st.subheader("4Ô∏è‚É£ Resultados e Relat√≥rios")
            
            # Determina qual resultado usar
            if st.session_state.enhanced_analysis_result:
                # An√°lise avan√ßada - mais tabs e visualiza√ß√µes
                tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                    "üîç An√°lise Avan√ßada", 
                    "üìä Dashboards Inteligentes", 
                    "üõ°Ô∏è Compliance & Frameworks",
                    "üìà Tend√™ncias & Predi√ß√µes",
                    "üéØ Centro de A√ß√µes",
                    "üíæ Relat√≥rios"
                ])
                
                with tab1:
                    render_enhanced_analysis_report(st.session_state.enhanced_analysis_result)
                
                with tab2:
                    # Dashboards Inteligentes (novo sistema personalizado)
                    render_enhanced_dashboards(st.session_state.enhanced_analysis_result)
                
                with tab3:
                    render_compliance_analysis(st.session_state.enhanced_analysis_result)
                
                with tab4:
                    render_trends_and_predictions(st.session_state.enhanced_analysis_result)
                
                with tab5:
                    render_action_center(st.session_state.enhanced_analysis_result)
                
                with tab6:
                    render_enhanced_export_options(st.session_state.enhanced_analysis_result)
                    
            else:
                # An√°lise padr√£o - tabs originais
                tab1, tab2, tab3 = st.tabs(["ü§ñ An√°lise da IA", "üìä Dashboards Visuais", "üíæ Exportar Relat√≥rio"])
                
                with tab1:
                    render_detailed_report(st.session_state.analysis_result)
                
                with tab2:
                    render_enhanced_dashboards(st.session_state.analysis_result)
                
                with tab3:
                    render_export_options(st.session_state.analysis_result)
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("üìã Gerar Relat√≥rio JSON", width='stretch', key="json_report_advanced"):
                        report_json = export_report_to_json(
                            st.session_state.analysis_result, 
                            st.session_state.governance_summary
                        )
                        st.download_button(
                            label="üíæ Download Relat√≥rio JSON",
                            data=report_json,
                            file_name=f"azure_governance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json",
                            width='stretch'
                        )
                
                with col2:
                    if st.button("üìä Gerar Relat√≥rio CSV", width='stretch', key="csv_report_advanced"):
                        if st.session_state.analysis_result.findings:
                            findings_df = pd.DataFrame([
                                {
                                    'Risk Level': f.risk_level.value,
                                    'Title': f.title,
                                    'Description': f.description,
                                    'Recommendation': f.recommendation,
                                    'Affected Count': len(f.affected_principals),
                                    'Affected Principals': '; '.join(f.affected_principals[:5])
                                }
                                for f in st.session_state.analysis_result.findings
                            ])
                            
                            csv_data = findings_df.to_csv(index=False)
                            st.download_button(
                                label="üíæ Download Relat√≥rio CSV",
                                data=csv_data,
                                file_name=f"azure_governance_findings_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv",
                                width='stretch'
                            )
                
                # Preview do relat√≥rio
                if st.session_state.analysis_result:
                    st.markdown("#### üëÄ Preview do Relat√≥rio")
                    preview_data = {
                        "total_findings": len(st.session_state.analysis_result.findings),
                        "risk_score": st.session_state.analysis_result.risk_assessment.score,
                        "summary": st.session_state.analysis_result.risk_assessment.summary
                    }
                    st.json(preview_data)

        # Footer
        st.markdown("---")
        st.markdown("""
        <div style='text-align: center; color: #666; padding: 2rem;'>
            <p>üõ°Ô∏è <strong>PrivIQ</strong> - Ferramenta de An√°lise de Governan√ßa para Microsoft Azure</p>
            <p>Desenvolvido para Hackathon | Vers√£o 2.0 | 2025</p>
        </div>
        """, unsafe_allow_html=True)
        
    except Exception as e:
        st.error(f"‚ùå Erro cr√≠tico na aplica√ß√£o: {str(e)}")
        st.error("Por favor, verifique se todos os arquivos est√£o presentes e corretos.")
        with st.expander("üîç Detalhes do erro"):
            st.exception(e)

if __name__ == "__main__":
    main()

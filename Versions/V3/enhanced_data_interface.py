# enhanced_data_interface.py

import streamlit as st
import asyncio
import json
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import pandas as pd

from azure_data_connectors import (
    DataSourceConfig, 
    UnifiedDataManager, 
    DataConnectorFactory,
    AzureLogAnalyticsConnector,
    AzureBlobStorageConnector
)
from config import config

class EnhancedDataInterface:
    """Interface melhorada para sele√ß√£o e configura√ß√£o de fontes de dados."""
    
    def __init__(self):
        self.data_manager = UnifiedDataManager()
        self.initialized_sources = set()
    
    def render_data_source_selector(self) -> Dict[str, Any]:
        """Renderiza interface para sele√ß√£o de fonte de dados."""
        
        st.subheader("üîå Configura√ß√£o de Fonte de Dados")
        
        # Sele√ß√£o do tipo de fonte
        source_type = st.selectbox(
            "Selecione a Fonte de Dados:",
            options=["manual", "azure_log_analytics", "azure_blob_storage", "hybrid"],
            format_func=self._format_source_option,
            help="Escolha como os logs ser√£o obtidos para an√°lise"
        )
        
        config_data = {"source_type": source_type}
        
        if source_type == "manual":
            config_data.update(self._render_manual_upload())
        elif source_type == "azure_log_analytics":
            config_data.update(self._render_log_analytics_config())
        elif source_type == "azure_blob_storage":
            config_data.update(self._render_blob_storage_config())
        elif source_type == "hybrid":
            config_data.update(self._render_hybrid_config())
        
        return config_data
    
    def _format_source_option(self, option: str) -> str:
        """Formata op√ß√µes de fonte de dados para exibi√ß√£o."""
        formats = {
            "manual": "üìÅ Upload Manual de Arquivo",
            "azure_log_analytics": "üìä Azure Log Analytics (Tempo Real)",
            "azure_blob_storage": "üíæ Azure Blob Storage",
            "hybrid": "üîÑ M√∫ltiplas Fontes (H√≠brido)"
        }
        return formats.get(option, option)
    
    def _render_manual_upload(self) -> Dict[str, Any]:
        """Interface para upload manual de arquivos."""
        st.info("üìÅ **Upload Manual**: Fa√ßa upload de arquivos JSON com logs de auditoria")
        
        uploaded_files = st.file_uploader(
            "Selecione arquivos de log (JSON)",
            type=['json'],
            accept_multiple_files=True,
            help="Fa√ßa upload de arquivos JSON contendo logs de auditoria do Azure"
        )
        
        return {
            "uploaded_files": uploaded_files,
            "data": self._process_uploaded_files(uploaded_files) if uploaded_files else []
        }
    
    def _render_log_analytics_config(self) -> Dict[str, Any]:
        """Interface simplificada para configura√ß√£o do Azure Log Analytics."""
        st.info("üìä **Azure Log Analytics**: Conex√£o configurada automaticamente")
        st.success(f"üîó Conectado ao Workspace: `{config.log_analytics_workspace_id[:8]}...`")
        
        # Apenas par√¢metros de consulta (credenciais v√™m do .env)
        st.subheader("‚öôÔ∏è Par√¢metros de Consulta")
        
        col3, col4 = st.columns(2)
        
        with col3:
            analysis_type = st.selectbox(
                "Tipo de An√°lise",
                options=[
                    "comprehensive_governance",
                    "role_assignments", 
                    "sign_in_analysis",
                    "privileged_operations"
                ],
                format_func=self._format_analysis_type
            )
            
            timeframe = st.selectbox(
                "Per√≠odo",
                options=["1d", "7d", "30d", "90d"],
                index=2,
                format_func=lambda x: f"√öltimos {x}"
            )
        
        with col4:
            limit = st.number_input(
                "Limite de Registros",
                min_value=100,
                max_value=50000,
                value=10000,
                step=500
            )
            
            user_filter = st.text_input(
                "Filtro de Usu√°rio (Opcional)",
                placeholder="nome@dominio.com",
                help="Filtrar logs por usu√°rio espec√≠fico"
            )
        
        # Teste de conex√£o usando credenciais do .env
        if st.button("üîç Testar Conex√£o", key="test_log_analytics"):
            connection_status = self._test_log_analytics_connection_with_env()
            if connection_status:
                st.success("‚úÖ Conex√£o estabelecida com sucesso!")
            else:
                st.error("‚ùå Falha na conex√£o. Verifique as configura√ß√µes no .env")
        
        return {
            "workspace_id": config.log_analytics_workspace_id,
            "tenant_id": config.log_analytics_tenant_id,
            "client_id": config.log_analytics_client_id,
            "client_secret": config.log_analytics_client_secret,
            "query_params": {
                "analysis_type": analysis_type,
                "timeframe": timeframe,
                "limit": limit,
                "user_filter": user_filter if user_filter else None
            }
        }
    
    def _render_blob_storage_config(self) -> Dict[str, Any]:
        """Interface simplificada para configura√ß√£o do Azure Blob Storage."""
        st.info("üíæ **Azure Blob Storage**: Configura√ß√£o autom√°tica")
        st.success(f"üîó Conectado √† Storage Account: `{config.storage_account_name}` | Container: `{config.storage_container_name}`")
        
        # Apenas par√¢metros de busca (credenciais v√™m do .env)
        st.subheader("üîç Par√¢metros de Busca")
        
        col3, col4 = st.columns(2)
        
        with col3:
            # Escolha entre prefixo ou nome espec√≠fico
            filter_type = st.radio(
                "Tipo de Filtro:",
                ["Prefixo", "Nome Espec√≠fico", "Todos os Arquivos"]
            )
            
            if filter_type == "Prefixo":
                blob_prefix = st.text_input(
                    "Prefixo dos Blobs",
                    value="",
                    help="Prefixo para filtrar blobs (ex: audit-logs/ ou AuditLogs_)"
                )
            elif filter_type == "Nome Espec√≠fico":
                blob_prefix = st.text_input(
                    "Nome Exato do Arquivo",
                    value="",
                    placeholder="Ex: AuditLogs_2025-08-20.json",
                    help="Nome completo do arquivo blob (incluindo extens√£o)"
                )
            else:
                blob_prefix = ""  # Buscar todos
            
            max_blobs = st.number_input(
                "M√°ximo de Blobs",
                min_value=1,
                max_value=1000,
                value=10 if filter_type == "Nome Espec√≠fico" else 100,
                help="N√∫mero m√°ximo de blobs a processar"
            )
        
        with col4:
            date_filter = st.date_input(
                "Filtro por Data (Opcional)",
                value=None,
                help="Processar apenas blobs ap√≥s esta data"
            )
        
        # Teste de conex√£o usando credenciais do .env
        if st.button("üîç Testar Conex√£o", key="test_blob_storage"):
            connection_status = self._test_blob_storage_connection_with_env()
            if connection_status:
                st.success("‚úÖ Conex√£o estabelecida com sucesso!")
            else:
                st.error("‚ùå Falha na conex√£o. Verifique as configura√ß√µes no .env")
        
        return {
            "storage_account_name": config.storage_account_name,
            "container_name": config.storage_container_name,
            "connection_string": config.storage_connection_string,  # USAR Connection String do .env
            "storage_connection_string": config.storage_connection_string,
            "query_params": {
                "blob_prefix": blob_prefix,
                "filter_type": filter_type,
                "max_blobs": max_blobs,
                "date_filter": date_filter
            }
        }
    
    def _render_hybrid_config(self) -> Dict[str, Any]:
        """Interface para configura√ß√£o h√≠brida (m√∫ltiplas fontes)."""
        st.info("üîÑ **Modo H√≠brido**: Combine dados de m√∫ltiplas fontes para an√°lise abrangente")
        
        st.subheader("üìä Fontes Ativas")
        
        # Sele√ß√£o de fontes
        use_log_analytics = st.checkbox(
            "üìà Incluir Azure Log Analytics",
            value=True,
            help="Dados em tempo real do workspace"
        )
        
        use_blob_storage = st.checkbox(
            "üíæ Incluir Azure Blob Storage", 
            value=True,
            help="Logs hist√≥ricos armazenados"
        )
        
        use_manual = st.checkbox(
            "üìÅ Incluir Upload Manual",
            value=False,
            help="Arquivos adicionais via upload"
        )
        
        hybrid_config = {"sources": []}
        
        if use_log_analytics:
            st.markdown("**Configura√ß√£o Log Analytics:**")
            la_config = self._render_log_analytics_config()
            hybrid_config["log_analytics"] = la_config
            hybrid_config["sources"].append("log_analytics")
        
        if use_blob_storage:
            st.markdown("**Configura√ß√£o Blob Storage:**")
            bs_config = self._render_blob_storage_config()
            hybrid_config["blob_storage"] = bs_config
            hybrid_config["sources"].append("blob_storage")
        
        if use_manual:
            st.markdown("**Upload Manual:**")
            manual_config = self._render_manual_upload()
            hybrid_config["manual"] = manual_config
            hybrid_config["sources"].append("manual")
        
        return hybrid_config
    
    def _format_analysis_type(self, analysis_type: str) -> str:
        """Formata tipos de an√°lise para exibi√ß√£o."""
        formats = {
            "comprehensive_governance": "üõ°Ô∏è An√°lise Completa de Governan√ßa",
            "role_assignments": "üë• Atribui√ß√µes de Roles",
            "sign_in_analysis": "üîê An√°lise de Sign-ins",
            "privileged_operations": "‚ö° Opera√ß√µes Privilegiadas"
        }
        return formats.get(analysis_type, analysis_type)
    
    def _process_uploaded_files(self, uploaded_files) -> List[Dict[str, Any]]:
        """Processa arquivos enviados manualmente."""
        all_logs = []
        
        if not uploaded_files:
            return all_logs
        
        for uploaded_file in uploaded_files:
            try:
                content = uploaded_file.read()
                logs = json.loads(content)
                
                if isinstance(logs, list):
                    all_logs.extend(logs)
                else:
                    all_logs.append(logs)
                
                st.success(f"‚úÖ Arquivo {uploaded_file.name} processado: {len(logs)} registros")
                
            except json.JSONDecodeError:
                st.error(f"‚ùå Erro ao processar {uploaded_file.name}: formato JSON inv√°lido")
            except Exception as e:
                st.error(f"‚ùå Erro inesperado com {uploaded_file.name}: {str(e)}")
        
        return all_logs
    
    def _test_log_analytics_connection_with_env(self) -> bool:
        """Testa conex√£o com Log Analytics usando credenciais do .env."""
        try:
            la_config = DataSourceConfig(
                source_type='log_analytics',
                workspace_id=config.log_analytics_workspace_id,
                tenant_id=config.log_analytics_tenant_id,
                client_id=config.log_analytics_client_id,
                client_secret=config.log_analytics_client_secret
            )
            
            connector = AzureLogAnalyticsConnector(la_config)
            return connector.validate_connection()
            
        except Exception as e:
            st.error(f"Erro no teste de conex√£o: {str(e)}")
            return False
    
    def _test_blob_storage_connection_with_env(self) -> bool:
        """Testa conex√£o com Blob Storage usando credenciais do .env."""
        try:
            bs_config = DataSourceConfig(
                source_type='storage_account',
                storage_account_name=config.storage_account_name,
                container_name=config.storage_container_name,
                storage_connection_string=config.storage_connection_string,
                storage_key=config.storage_key
            )
            
            connector = AzureBlobStorageConnector(bs_config)
            return connector.validate_connection()
            
        except Exception as e:
            st.error(f"Erro no teste de conex√£o: {str(e)}")
            return False

    def _test_log_analytics_connection(self, workspace_id: str, tenant_id: str, 
                                     client_id: str = "", client_secret: str = "") -> bool:
        """Testa conex√£o com Log Analytics."""
        try:
            la_config = DataSourceConfig(
                source_type='log_analytics',
                workspace_id=workspace_id,
                tenant_id=tenant_id,
                client_id=client_id if client_id else None,
                client_secret=client_secret if client_secret else None
            )
            
            connector = AzureLogAnalyticsConnector(la_config)
            return connector.validate_connection()
            
        except Exception as e:
            st.error(f"Erro no teste de conex√£o: {str(e)}")
            return False
    
    def _test_blob_storage_connection(self, storage_account: str, container_name: str, 
                                    connection_string: str = "") -> bool:
        """Testa conex√£o com Blob Storage."""
        try:
            bs_config = DataSourceConfig(
                source_type='storage_account',
                storage_account_name=storage_account,
                container_name=container_name,
                connection_string=connection_string if connection_string else None
            )
            
            connector = AzureBlobStorageConnector(bs_config)
            return connector.validate_connection()
            
        except Exception as e:
            st.error(f"Erro no teste de conex√£o: {str(e)}")
            return False
    
    async def fetch_data_async(self, config_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Busca dados de forma ass√≠ncrona baseado na configura√ß√£o."""
        
        source_type = config_data["source_type"]
        
        if source_type == "manual":
            return config_data.get("data", [])
        
        elif source_type == "azure_log_analytics":
            return await self._fetch_log_analytics_data(config_data)
        
        elif source_type == "azure_blob_storage":
            return await self._fetch_blob_storage_data(config_data)
        
        elif source_type == "hybrid":
            return await self._fetch_hybrid_data(config_data)
        
        return []
    
    async def _fetch_log_analytics_data(self, config_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Busca dados do Log Analytics."""
        la_config = DataSourceConfig(
            source_type='log_analytics',
            workspace_id=config_data["workspace_id"],
            tenant_id=config_data["tenant_id"],
            client_id=config_data.get("client_id"),
            client_secret=config_data.get("client_secret")
        )
        
        connector = AzureLogAnalyticsConnector(la_config)
        self.data_manager.register_connector("log_analytics", connector)
        
        return await connector.fetch_data(config_data["query_params"])
    
    async def _fetch_blob_storage_data(self, config_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Busca dados do Blob Storage."""
        bs_config = DataSourceConfig(
            source_type='storage_account',
            storage_account_name=config_data["storage_account_name"],
            container_name=config_data["container_name"],
            connection_string=config_data.get("connection_string"),
            storage_connection_string=config_data.get("storage_connection_string"),
            storage_key=config.storage_key
        )
        
        connector = AzureBlobStorageConnector(bs_config)
        self.data_manager.register_connector("blob_storage", connector)
        
        return await connector.fetch_data(config_data["query_params"])
    
    async def _fetch_hybrid_data(self, config_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Busca dados de m√∫ltiplas fontes."""
        all_data = []
        
        # Registra conectores baseado na configura√ß√£o
        for source in config_data["sources"]:
            if source == "log_analytics" and "log_analytics" in config_data:
                la_data = await self._fetch_log_analytics_data(config_data["log_analytics"])
                all_data.extend(la_data)
            
            elif source == "blob_storage" and "blob_storage" in config_data:
                bs_data = await self._fetch_blob_storage_data(config_data["blob_storage"])
                all_data.extend(bs_data)
            
            elif source == "manual" and "manual" in config_data:
                manual_data = config_data["manual"].get("data", [])
                all_data.extend(manual_data)
        
        return all_data
    
    def render_data_summary(self, data: List[Dict[str, Any]]):
        """Renderiza resumo dos dados obtidos."""
        if not data:
            st.warning("‚ö†Ô∏è Nenhum dado foi obtido das fontes configuradas")
            return
        
        st.success(f"‚úÖ **{len(data):,}** registros obtidos com sucesso!")
        
        # M√©tricas r√°pidas
        col1, col2, col3, col4 = st.columns(4)
        
        df = pd.DataFrame(data)
        
        with col1:
            unique_users = len(df.get('user_principal_name', pd.Series()).dropna().unique()) if 'user_principal_name' in df.columns else 0
            st.metric("üë• Usu√°rios √önicos", unique_users)
        
        with col2:
            unique_operations = len(df.get('operation_name', pd.Series()).dropna().unique()) if 'operation_name' in df.columns else 0
            st.metric("‚öôÔ∏è Opera√ß√µes √önicas", unique_operations)
        
        with col3:
            date_range = "N/A"
            if 'timestamp' in df.columns or 'TimeGenerated' in df.columns:
                time_col = 'timestamp' if 'timestamp' in df.columns else 'TimeGenerated'
                df[time_col] = pd.to_datetime(df[time_col], errors='coerce')
                min_date = df[time_col].min()
                max_date = df[time_col].max()
                if pd.notna(min_date) and pd.notna(max_date):
                    days = (max_date - min_date).days
                    date_range = f"{days} dias"
            st.metric("üìÖ Per√≠odo", date_range)
        
        with col4:
            data_size = len(json.dumps(data).encode('utf-8')) / 1024 / 1024  # MB
            st.metric("üíæ Tamanho", f"{data_size:.1f} MB")
        
        # Preview dos dados
        with st.expander("üîç Preview dos Dados (Primeiros 5 registros)"):
            if len(df) > 0:
                st.dataframe(df.head(), use_container_width=True)
            else:
                st.info("Nenhum dado para exibir")

# Fun√ß√£o auxiliar para uso no app principal
def render_enhanced_data_interface() -> tuple[Dict[str, Any], List[Dict[str, Any]]]:
    """Renderiza interface aprimorada e retorna configura√ß√£o e dados."""
    
    interface = EnhancedDataInterface()
    
    # Renderiza seletor de fonte
    config_data = interface.render_data_source_selector()
    
    # Bot√£o para buscar dados
    if st.button("üöÄ Buscar Dados", type="primary", use_container_width=True):
        with st.spinner("Buscando dados das fontes configuradas..."):
            try:
                # Executa busca ass√≠ncrona
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                data = loop.run_until_complete(interface.fetch_data_async(config_data))
                loop.close()
                
                # Armazena dados na sess√£o
                st.session_state['fetched_data'] = data
                st.session_state['data_config'] = config_data
                
                # Renderiza resumo
                interface.render_data_summary(data)
                
                return config_data, data
                
            except Exception as e:
                st.error(f"‚ùå Erro ao buscar dados: {str(e)}")
                return config_data, []
    
    # Retorna dados da sess√£o se existirem
    if 'fetched_data' in st.session_state:
        data = st.session_state['fetched_data']
        interface.render_data_summary(data)
        return st.session_state.get('data_config', config_data), data
    
    return config_data, []